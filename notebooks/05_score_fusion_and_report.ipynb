{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Score Fusion & Report Generation\n",
    "\n",
    "This notebook demonstrates the final step: combining all three similarity signals with student-safe bias and generating academic reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from src.fusion import PlagiarismScorer\n",
    "from src.reporting import ExplanationGenerator\n",
    "from src.io import load_submissions\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Score Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Three-Signal Score Fusion\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSimilarity Weights:\")\n",
    "print(\"  ‚Ä¢ Lexical:     15% (weak signal - supporting evidence only)\")\n",
    "print(\"  ‚Ä¢ Structural:  45% (strong signal - algorithmic structure)\")\n",
    "print(\"  ‚Ä¢ Semantic:    40% (strong signal - intent analysis)\")\n",
    "print(\"\\nStudent-Safe Bias Adjustments:\")\n",
    "print(\"  ‚úì Penalize if only lexical similarity is high\")\n",
    "print(\"  ‚úì Boost when structural + semantic agree\")\n",
    "print(\"  ‚úì Reduce score on high signal uncertainty\")\n",
    "print(\"\\nSeverity Thresholds:\")\n",
    "print(\"  üö® Severe:  ‚â•90% (near-exact logic copying)\")\n",
    "print(\"  ‚ö†Ô∏è  Partial: 60-89% (core logic copied)\")\n",
    "print(\"  ‚úÖ Clean:   <60% (original work)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Score Fusion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scorer\n",
    "scorer = PlagiarismScorer()\n",
    "\n",
    "# Test with example code\n",
    "code1 = '''\n",
    "def factorial(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * factorial(n-1)\n",
    "'''\n",
    "\n",
    "code2 = '''\n",
    "def compute_fact(x):\n",
    "    if x <= 1:\n",
    "        return 1\n",
    "    return x * compute_fact(x-1)\n",
    "'''\n",
    "\n",
    "# Compute similarity\n",
    "result = scorer.compute_similarity(code1, code2, language='python', normalize=True)\n",
    "\n",
    "print(\"üìä Score Fusion Example\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nRaw Score (before bias): {result['raw_score']:.1f}%\")\n",
    "print(f\"Final Score (after bias): {result['final_score']:.1f}%\")\n",
    "print(f\"\\nBreakdown:\")\n",
    "for signal, score in result['breakdown'].items():\n",
    "    print(f\"  {signal.capitalize() + ':':12} {score:.1f}%\")\n",
    "\n",
    "print(f\"\\nStructural Method: {result['structural_method']}\")\n",
    "if result['structural_breakdown']:\n",
    "    print(f\"Structural Breakdown:\")\n",
    "    for method, score in result['structural_breakdown'].items():\n",
    "        print(f\"  {method.upper():8} {score:.1f}%\")\n",
    "\n",
    "print(f\"\\nSeverity: {result['severity'].upper()}\")\n",
    "\n",
    "if result['adjustments']:\n",
    "    print(f\"\\nStudent-Safe Adjustments:\")\n",
    "    for adj in result['adjustments']:\n",
    "        print(f\"  ‚Ä¢ {adj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Signal Contribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract signal contributions\n",
    "from src.config.settings import SIMILARITY_WEIGHTS\n",
    "\n",
    "signals = ['Lexical', 'Structural', 'Semantic']\n",
    "raw_scores = [\n",
    "    result['breakdown']['lexical'],\n",
    "    result['breakdown']['structural'],\n",
    "    result['breakdown']['semantic']\n",
    "]\n",
    "weights = [\n",
    "    SIMILARITY_WEIGHTS['lexical'],\n",
    "    SIMILARITY_WEIGHTS['structural'],\n",
    "    SIMILARITY_WEIGHTS['semantic']\n",
    "]\n",
    "contributions = [score * weight for score, weight in zip(raw_scores, weights)]\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Raw scores\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "bars1 = ax1.bar(signals, raw_scores, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, score in zip(bars1, raw_scores):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{score:.1f}%',\n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax1.set_ylabel('Similarity Score (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Raw Similarity Scores', fontsize=14, fontweight='bold', pad=15)\n",
    "ax1.set_ylim(0, 110)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Weighted contributions\n",
    "bars2 = ax2.bar(signals, contributions, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, contrib, weight in zip(bars2, contributions, weights):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{contrib:.1f}%\\n({weight:.0%})',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax2.set_ylabel('Contribution to Final Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Weighted Contributions', fontsize=14, fontweight='bold', pad=15)\n",
    "ax2.set_ylim(0, 60)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Final Score = {result[\"final_score\"]:.1f}% (after student-safe adjustments)',\n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyzing Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submissions\n",
    "submissions = load_submissions('../data/raw/sample_submissions.csv')\n",
    "\n",
    "# Analyze all\n",
    "print(\"Analyzing all submissions...\\n\")\n",
    "results = scorer.analyze_all(submissions, normalize=True)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã Analysis Summary\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for res in results:\n",
    "    severity_emoji = {\n",
    "        'severe': 'üö®',\n",
    "        'partial': '‚ö†Ô∏è ',\n",
    "        'clean': '‚úÖ'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{severity_emoji[res['severity']]} {res['submission_id']}\")\n",
    "    print(f\"   Similarity: {res['similarity_score']:.1f}%\")\n",
    "    print(f\"   Most similar to: {res['most_similar_to']}\")\n",
    "    print(f\"   Severity: {res['severity'].upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Severity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count severity levels\n",
    "from collections import Counter\n",
    "\n",
    "severity_counts = Counter([r['severity'] for r in results])\n",
    "\n",
    "# Visualize\n",
    "severities = ['clean', 'partial', 'severe']\n",
    "counts = [severity_counts.get(s, 0) for s in severities]\n",
    "colors_sev = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "labels = ['Clean\\n(<60%)', 'Partial\\n(60-89%)', 'Severe\\n(‚â•90%)']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Pie chart\n",
    "ax1.pie(counts, labels=labels, autopct='%1.0f%%', colors=colors_sev,\n",
    "        startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "ax1.set_title('Severity Distribution', fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "# Bar chart\n",
    "bars = ax2.bar(labels, counts, color=colors_sev, alpha=0.7, \n",
    "               edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{count}',\n",
    "             ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax2.set_ylabel('Number of Submissions', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Severity Counts', fontsize=14, fontweight='bold', pad=15)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal submissions: {len(results)}\")\n",
    "for sev, count in severity_counts.items():\n",
    "    percentage = count / len(results) * 100\n",
    "    print(f\"  {sev.capitalize():8} {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Academic Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize report generator\n",
    "reporter = ExplanationGenerator()\n",
    "\n",
    "# Generate report for highest similarity submission\n",
    "sorted_results = sorted(results, key=lambda x: x['similarity_score'], reverse=True)\n",
    "top_result = sorted_results[0]\n",
    "\n",
    "# Find the submission data\n",
    "sub_data = next(s for s in submissions if s['submission_id'] == top_result['submission_id'])\n",
    "\n",
    "# Generate report\n",
    "report = reporter.generate_report(\n",
    "    submission_id=top_result['submission_id'],\n",
    "    similarity_score=top_result['similarity_score'],\n",
    "    breakdown=top_result['breakdown'],\n",
    "    severity=top_result['severity'],\n",
    "    most_similar_to=top_result['most_similar_to'],\n",
    "    code=sub_data['code'],\n",
    "    adjustments=top_result.get('adjustments', [])\n",
    ")\n",
    "\n",
    "# Print formatted report\n",
    "print(reporter.format_text_report(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare All Signals for Top Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top similar pair\n",
    "top_pair = sorted_results[0]\n",
    "\n",
    "# Extract breakdown\n",
    "breakdown = top_pair['breakdown']\n",
    "\n",
    "# Create radar chart\n",
    "from math import pi\n",
    "\n",
    "categories = ['Lexical', 'Structural', 'Semantic']\n",
    "values = [breakdown['lexical'], breakdown['structural'], breakdown['semantic']]\n",
    "values += values[:1]  # Complete the circle\n",
    "\n",
    "angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "ax.plot(angles, values, 'o-', linewidth=2, color='#e74c3c', label='Similarity')\n",
    "ax.fill(angles, values, alpha=0.25, color='#e74c3c')\n",
    "\n",
    "# Add threshold circles\n",
    "ax.plot(angles, [90]*len(angles), '--', linewidth=1, color='red', alpha=0.5, label='Severe (90%)')\n",
    "ax.plot(angles, [60]*len(angles), '--', linewidth=1, color='orange', alpha=0.5, label='Partial (60%)')\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, fontsize=12, fontweight='bold')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks([20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'], fontsize=10)\n",
    "ax.grid(True)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "plt.title(f'Three-Signal Analysis\\n{top_pair[\"submission_id\"]} (Most Similar Submission)',\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Final Score: {top_pair['similarity_score']:.1f}%\")\n",
    "print(f\"   Verdict: {top_pair['severity'].upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save results to JSON\n",
    "output_data = {\n",
    "    'analysis_summary': {\n",
    "        'total_submissions': len(results),\n",
    "        'severity_distribution': dict(severity_counts)\n",
    "    },\n",
    "    'results': results\n",
    "}\n",
    "\n",
    "with open('../data/results/plagiarism_analysis.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(\"‚úì Results saved to data/results/plagiarism_analysis.json\")\n",
    "\n",
    "# Create DataFrame for easy viewing\n",
    "df = pd.DataFrame([{\n",
    "    'Submission': r['submission_id'],\n",
    "    'Similarity': f\"{r['similarity_score']:.1f}%\",\n",
    "    'Most Similar To': r['most_similar_to'],\n",
    "    'Severity': r['severity'].upper(),\n",
    "    'Lexical': f\"{r['breakdown']['lexical']:.1f}%\",\n",
    "    'Structural': f\"{r['breakdown']['structural']:.1f}%\",\n",
    "    'Semantic': f\"{r['breakdown']['semantic']:.1f}%\"\n",
    "} for r in sorted_results])\n",
    "\n",
    "print(\"\\nüìä Final Results Summary:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Score Fusion Process\n",
    "\n",
    "1. **Three Signals**: Lexical (15%) + Structural (45%) + Semantic (40%)\n",
    "2. **Raw Score**: Weighted combination of all three\n",
    "3. **Student-Safe Bias**: Adjustments to avoid false positives\n",
    "4. **Final Score**: bias-adjusted similarity percentage\n",
    "5. **Severity Classification**: Severe (‚â•90%) / Partial (60-89%) / Clean (<60%)\n",
    "\n",
    "### Student-Safe Philosophy in Action\n",
    "\n",
    "‚úÖ **Never relies on single signal** - All three must support the verdict\n",
    "\n",
    "‚úÖ **Penalizes lexical-only matches** - Surface similarity isn't enough\n",
    "\n",
    "‚úÖ **Boosts multi-signal agreement** - Higher confidence when all agree\n",
    "\n",
    "‚úÖ **Reduces uncertain scores** - High variance = lower confidence\n",
    "\n",
    "### Report Generation\n",
    "\n",
    "‚úÖ **Adaptive Depth**: More detailed explanations for high-similarity cases\n",
    "\n",
    "‚úÖ **Academic Language**: Professional, fair, evidence-based\n",
    "\n",
    "‚úÖ **Clear Penalties**: Specific recommendations based on severity\n",
    "\n",
    "**Key Takeaway**: The fusion system is designed to be **conservative** - it only flags severe plagiarism when there's strong evidence across multiple independent signals. This protects students from false accusations while still catching real cheating!\n",
    "\n",
    "**Congratulations!** You've completed the full plagiarism detection pipeline. The system is now ready for deployment and real-world testing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
