{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Code Normalization\n",
    "\n",
    "This notebook demonstrates code normalization - the critical first step that makes plagiarism detection robust to cosmetic changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.normalization import get_normalizer, PythonNormalizer\n",
    "from src.io import load_submissions\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before vs After: Python Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code with various cosmetic differences\n",
    "original_code = '''\n",
    "def calculate_fibonacci(number):\n",
    "    \"\"\"Calculate fibonacci number recursively.\"\"\"\n",
    "    # Base case\n",
    "    if number <= 1:\n",
    "        return number\n",
    "    # Recursive case\n",
    "    return calculate_fibonacci(number - 1) + calculate_fibonacci(number - 2)\n",
    "'''\n",
    "\n",
    "# Initialize normalizer\n",
    "normalizer = PythonNormalizer()\n",
    "\n",
    "# Normalize\n",
    "normalized_code = normalizer.normalize(original_code)\n",
    "\n",
    "# Display side-by-side\n",
    "print(\"=\" * 80)\n",
    "print(\"BEFORE NORMALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "print(original_code)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AFTER NORMALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "print(normalized_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identifier Mapping\n",
    "\n",
    "See how variable and function names are normalized to canonical forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get identifier mapping\n",
    "identifier_map = normalizer.get_identifier_map()\n",
    "\n",
    "print(\"ðŸ“‹ Identifier Mapping\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Original Name':<30} {'Normalized Name':<20}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for original, normalized in identifier_map.items():\n",
    "    print(f\"{original:<30} {normalized:<20}\")\n",
    "\n",
    "print(f\"\\nTotal identifiers normalized: {len(identifier_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing with Disguised Plagiarism\n",
    "\n",
    "Let's test with two codes that are identical in logic but look different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code\n",
    "code1 = '''\n",
    "def factorial(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * factorial(n-1)\n",
    "'''\n",
    "\n",
    "# \"Disguised\" version - renamed variables, added comments\n",
    "code2 = '''\n",
    "def compute_fact(num):\n",
    "    # Base case for recursion\n",
    "    if num <= 1:\n",
    "        return 1\n",
    "    # Recursive multiplication\n",
    "    return num * compute_fact(num - 1)\n",
    "'''\n",
    "\n",
    "# Normalize both\n",
    "norm1 = normalizer.normalize(code1)\n",
    "normalizer.reset_counters()\n",
    "norm2 = normalizer.normalize(code2)\n",
    "\n",
    "print(\"ðŸ” Disguised Plagiarism Test\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nORIGINAL CODE 1:\")\n",
    "print(code1)\n",
    "print(\"\\nDISGUISED CODE 2:\")\n",
    "print(code2)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NORMALIZED CODE 1:\")\n",
    "print(norm1)\n",
    "print(\"\\nNORMALIZED CODE 2:\")\n",
    "print(norm2)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Check if identical after normalization\n",
    "if norm1.strip() == norm2.strip():\n",
    "    print(\"\\nâœ… SUCCESS: Normalized codes are IDENTICAL!\")\n",
    "    print(\"   Normalization successfully removed cosmetic differences.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Normalized codes differ slightly (but are very similar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalization Effect on Code Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submissions\n",
    "submissions = load_submissions('../data/raw/sample_submissions.csv')\n",
    "\n",
    "# Normalize all and compare lengths\n",
    "original_lengths = []\n",
    "normalized_lengths = []\n",
    "submission_ids = []\n",
    "\n",
    "for sub in submissions:\n",
    "    original_lengths.append(len(sub['code']))\n",
    "    \n",
    "    normalizer.reset_counters()\n",
    "    normalized = normalizer.normalize(sub['code'])\n",
    "    normalized_lengths.append(len(normalized))\n",
    "    \n",
    "    submission_ids.append(sub['submission_id'])\n",
    "\n",
    "# Visualize\n",
    "x = range(len(submission_ids))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar([i - width/2 for i in x], original_lengths, width, \n",
    "               label='Original', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar([i + width/2 for i in x], normalized_lengths, width,\n",
    "               label='Normalized', color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Submission ID', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Code Length (characters)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Code Length: Before vs After Normalization', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(submission_ids)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "avg_reduction = (sum(original_lengths) - sum(normalized_lengths)) / len(submissions)\n",
    "print(f\"\\nðŸ“Š Average length reduction: {avg_reduction:.1f} characters\")\n",
    "print(f\"   (Comments, docstrings, and whitespace removed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing Different Normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_code = '''\n",
    "class BinarySearch:\n",
    "    \"\"\"Binary search implementation.\"\"\"\n",
    "    \n",
    "    def search(self, array, target):\n",
    "        # Initialize pointers\n",
    "        left_pointer = 0\n",
    "        right_pointer = len(array) - 1\n",
    "        \n",
    "        while left_pointer <= right_pointer:\n",
    "            middle = (left_pointer + right_pointer) // 2\n",
    "            \n",
    "            if array[middle] == target:\n",
    "                return middle\n",
    "            elif array[middle] < target:\n",
    "                left_pointer = middle + 1\n",
    "            else:\n",
    "                right_pointer = middle - 1\n",
    "        \n",
    "        return -1  # Not found\n",
    "'''\n",
    "\n",
    "# Normalize\n",
    "normalizer.reset_counters()\n",
    "normalized = normalizer.normalize(test_code)\n",
    "\n",
    "print(\"ðŸ“ Complex Code Normalization Example\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nORIGINAL:\")\n",
    "print(test_code)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NORMALIZED:\")\n",
    "print(normalized)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Show identifier mapping\n",
    "print(\"\\nIdentifier Mapping:\")\n",
    "for orig, norm in normalizer.get_identifier_map().items():\n",
    "    print(f\"  {orig:20} â†’ {norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization: Normalization Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count what gets removed\n",
    "sample_code = original_code\n",
    "\n",
    "# Count components\n",
    "comment_lines = sample_code.count('#')\n",
    "docstring_count = sample_code.count('\"\"\"') // 2\n",
    "blank_lines = sample_code.count('\\n\\n')\n",
    "total_lines = sample_code.count('\\n') + 1\n",
    "code_lines = total_lines - comment_lines - docstring_count - blank_lines\n",
    "\n",
    "# Pie chart\n",
    "components = ['Code Lines', 'Comments', 'Docstrings', 'Blank Lines']\n",
    "counts = [code_lines, comment_lines, docstring_count, blank_lines]\n",
    "colors = ['#2ecc71', '#e74c3c', '#3498db', '#95a5a6']\n",
    "explode = (0.05, 0, 0, 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(counts, labels=components, autopct='%1.1f%%', startangle=90,\n",
    "        colors=colors, explode=explode, shadow=True, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "plt.title('Code Composition Before Normalization', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Normalization removes everything except actual code logic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Comment Removal**: All comments and docstrings removed\n",
    "\n",
    "âœ… **Identifier Normalization**: Variables â†’ var_1, var_2; Functions â†’ func_1, func_2\n",
    "\n",
    "âœ… **Whitespace Normalization**: Consistent formatting\n",
    "\n",
    "âœ… **Cosmetic-Proof**: Disguised plagiarism becomes obvious after normalization\n",
    "\n",
    "**Key Insight**: Normalization is what makes the system robust to trivial changes like renaming variables or adding comments. Two codes with identical logic will look nearly identical after normalization!\n",
    "\n",
    "**Next Steps**: Proceed to notebook 02 to see lexical similarity analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
