{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Semantic Similarity with Code Embeddings\n",
    "\n",
    "This notebook demonstrates **semantic similarity** - using ML-based code embeddings to understand algorithmic intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.similarity.semantic import SemanticSimilarity\n",
    "from src.io import load_submissions\n",
    "from src.normalization import get_normalizer\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Semantic Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize semantic similarity\n",
    "semantic_analyzer = SemanticSimilarity()\n",
    "\n",
    "print(\"ü§ñ Semantic Similarity Using Code Embeddings\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThis analyzer uses:\")\n",
    "print(\"  ‚Ä¢ CodeBERT (if transformers available)\")\n",
    "print(\"  ‚Ä¢ Falls back to lexical similarity if not\")\n",
    "print(\"\\nSemantic similarity captures:\")\n",
    "print(\"  ‚úì Algorithmic intent\")\n",
    "print(\"  ‚úì Problem-solving approach\")\n",
    "print(\"  ‚úì Logic patterns\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test: Same Algorithm, Different Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive binary search\n",
    "binary_search_recursive = '''\n",
    "def binary_search(arr, target, left, right):\n",
    "    if left > right:\n",
    "        return -1\n",
    "    mid = (left + right) // 2\n",
    "    if arr[mid] == target:\n",
    "        return mid\n",
    "    elif arr[mid] < target:\n",
    "        return binary_search(arr, target, mid + 1, right)\n",
    "    else:\n",
    "        return binary_search(arr, target, left, mid - 1)\n",
    "'''\n",
    "\n",
    "# Iterative binary search\n",
    "binary_search_iterative = '''\n",
    "def binary_search(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "'''\n",
    "\n",
    "# Compute similarity\n",
    "similarity = semantic_analyzer.compute_similarity(\n",
    "    binary_search_recursive,\n",
    "    binary_search_iterative\n",
    ")\n",
    "\n",
    "print(\"üß™ TEST: Binary Search - Recursive vs Iterative\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nSemantic Similarity: {similarity:.1f}%\")\n",
    "print(\"\\nüí° Semantic analysis should recognize these as the SAME algorithm\")\n",
    "print(\"   despite different implementation styles!\")\n",
    "\n",
    "if similarity > 70:\n",
    "    print(\"\\n‚úÖ SUCCESS: Recognized same algorithmic intent!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Note: Score is {similarity:.1f}% (may be using fallback method)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test: Different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bubble sort\n",
    "bubble_sort = '''\n",
    "def sort_array(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "'''\n",
    "\n",
    "# Quick sort\n",
    "quick_sort = '''\n",
    "def sort_array(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    return sort_array(left) + middle + sort_array(right)\n",
    "'''\n",
    "\n",
    "similarity2 = semantic_analyzer.compute_similarity(bubble_sort, quick_sort)\n",
    "\n",
    "print(\"üß™ TEST: Bubble Sort vs Quick Sort\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nSemantic Similarity: {similarity2:.1f}%\")\n",
    "print(\"\\nüí° These are DIFFERENT algorithms (both solve sorting)\")\n",
    "print(\"   Should have moderate similarity (same problem, different approach)\")\n",
    "\n",
    "if 40 < similarity2 < 70:\n",
    "    print(\"\\n‚úÖ SUCCESS: Correctly identified as related but different!\")\n",
    "elif similarity2 > 70:\n",
    "    print(\"\\n‚ö†Ô∏è  Similarity is high - may indicate same problem domain\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Similarity is low - clearly different approaches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize submissions\n",
    "submissions = load_submissions('../data/raw/sample_submissions.csv')\n",
    "normalizer = get_normalizer('python')\n",
    "\n",
    "normalized_codes = []\n",
    "for sub in submissions:\n",
    "    normalizer.reset_counters()\n",
    "    normalized_codes.append(normalizer.normalize(sub['code']))\n",
    "\n",
    "# Compute pairwise semantic similarities\n",
    "n = len(submissions)\n",
    "semantic_matrix = np.zeros((n, n))\n",
    "\n",
    "print(f\"Computing semantic similarity for {n} submissions...\\n\")\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i == j:\n",
    "            semantic_matrix[i][j] = 100\n",
    "        elif i < j:\n",
    "            sim = semantic_analyzer.compute_similarity(\n",
    "                normalized_codes[i],\n",
    "                normalized_codes[j]\n",
    "            )\n",
    "            semantic_matrix[i][j] = sim\n",
    "            semantic_matrix[j][i] = sim\n",
    "            print(f\"  {submissions[i]['submission_id']} ‚Üî {submissions[j]['submission_id']}: {sim:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úì Semantic similarity matrix computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Similarity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ids = [sub['submission_id'] for sub in submissions]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(semantic_matrix,\n",
    "                 annot=True,\n",
    "                 fmt='.1f',\n",
    "                 cmap='viridis',\n",
    "                 vmin=0,\n",
    "                 vmax=100,\n",
    "                 xticklabels=submission_ids,\n",
    "                 yticklabels=submission_ids,\n",
    "                 cbar_kws={'label': 'Semantic Similarity (%)'},\n",
    "                 linewidths=0.5,\n",
    "                 linecolor='white')\n",
    "\n",
    "plt.title('Semantic Similarity Heatmap\\n(Algorithmic Intent Analysis)',\n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Submission ID', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Submission ID', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Top Semantically Similar Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar pairs\n",
    "pairs = []\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        pairs.append({\n",
    "            'id1': submission_ids[i],\n",
    "            'id2': submission_ids[j],\n",
    "            'similarity': semantic_matrix[i][j]\n",
    "        })\n",
    "\n",
    "pairs.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "print(\"üîù Top Semantically Similar Pairs\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Rank':<6} {'Pair':<20} {'Semantic Similarity':<20} {'Assessment'}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, pair in enumerate(pairs[:5], 1):\n",
    "    sim = pair['similarity']\n",
    "    \n",
    "    if sim >= 90:\n",
    "        assessment = \"üö® Very High - Investigate\"\n",
    "    elif sim >= 70:\n",
    "        assessment = \"‚ö†Ô∏è  High - Likely similar\"\n",
    "    elif sim >= 50:\n",
    "        assessment = \"üìä Moderate - Same problem\"\n",
    "    else:\n",
    "        assessment = \"‚úÖ Low - Different approaches\"\n",
    "    \n",
    "    pair_str = f\"{pair['id1']} ‚Üî {pair['id2']}\"\n",
    "    print(f\"{i:<6} {pair_str:<20} {sim:<20.1f} {assessment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Semantic vs Lexical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.similarity.lexical import LexicalSimilarity\n",
    "\n",
    "# Compare semantic vs lexical for top pair\n",
    "if pairs:\n",
    "    top_pair = pairs[0]\n",
    "    idx1 = submission_ids.index(top_pair['id1'])\n",
    "    idx2 = submission_ids.index(top_pair['id2'])\n",
    "    \n",
    "    # Get lexical similarity\n",
    "    lexical_analyzer = LexicalSimilarity()\n",
    "    lexical_sim = lexical_analyzer.compute_similarity(\n",
    "        normalized_codes[idx1],\n",
    "        normalized_codes[idx2]\n",
    "    )\n",
    "    \n",
    "    semantic_sim = top_pair['similarity']\n",
    "    \n",
    "    # Visualize comparison\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    methods = ['Lexical\\n(Token-based)', 'Semantic\\n(Intent-based)']\n",
    "    scores = [lexical_sim, semantic_sim]\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    \n",
    "    bars = ax.bar(methods, scores, color=colors, alpha=0.7, \n",
    "                  edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, score in zip(bars, scores):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{score:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Similarity Score (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Lexical vs Semantic Similarity\\nMost Similar Pair: {top_pair[\"id1\"]} ‚Üî {top_pair[\"id2\"]}',\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Comparison for {top_pair['id1']} ‚Üî {top_pair['id2']}:\")\n",
    "    print(f\"   Lexical:  {lexical_sim:.1f}% (surface-level tokens)\")\n",
    "    print(f\"   Semantic: {semantic_sim:.1f}% (algorithmic intent)\")\n",
    "    \n",
    "    diff = abs(semantic_sim - lexical_sim)\n",
    "    if diff > 20:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Large difference ({diff:.1f}%) - semantic captures deeper similarity!\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úì Methods agree (difference: {diff:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **Algorithmic Intent**: Semantic similarity understands what the code is trying to do\n",
    "\n",
    "‚úÖ **Implementation-Agnostic**: Recognizes same algorithm in different styles\n",
    "\n",
    "‚úÖ **Strong Signal**: Gets 40% weight in final score (tied with structural)\n",
    "\n",
    "‚ö†Ô∏è **Model Dependent**: Requires CodeBERT/transformers (falls back to lexical if unavailable)\n",
    "\n",
    "**Key Insight**: Semantic similarity is crucial for detecting plagiarism when students:\n",
    "- Use the same algorithm but different variable names\n",
    "- Switch between recursive/iterative implementations\n",
    "- Reorganize code structure but keep the same logic\n",
    "\n",
    "**Next Steps**: Proceed to notebook 05 to see how all three signals combine in score fusion!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
